# -*- coding: utf-8 -*-
"""Interface.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vm1kcWAXCWv5dNeFN41pzBZksmXF3NMm

# EstalaÃ§Ãµes e download da database
"""

!wget -O listings.csv.gz "https://data.insideairbnb.com/brazil/rj/rio-de-janeiro/2025-03-19/data/listings.csv.gz"

!gunzip -k listings.csv.gz

!pip install gradio matplotlib seaborn pandas scikit-learn lazypredict

"""# **Bibliotecas**"""

# Commented out IPython magic to ensure Python compatibility.
import gradio as gr
import seaborn as sns
import pandas as pd
from os import name
import matplotlib.pyplot as plt
import torch
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from lazypredict.Supervised import LazyRegressor
from torch.utils.data import TensorDataset, DataLoader, Subset, random_split
import torch.nn as nn
import torch.optim as optim
# %matplotlib inline
plt.style.use('fivethirtyeight')
import numpy as np
import datetime
from torch.utils.data import Dataset, TensorDataset, DataLoader
from torch.utils.data.dataset import random_split

pd.set_option('display.max_columns', None)

df = pd.read_csv("listings.csv")
df.head()

target_columns = [
    "accommodates",      # Number of guests the property can host
    "bathrooms",         # Number of bathrooms available
    "bedrooms",          # Number of bedrooms available
    "beds",              # Number of beds available
    "minimum_nights",    # Minimum nights required for a booking
    "maximum_nights",    # Maximum nights allowed for a booking
    "number_of_reviews", # Total reviews given by past guests
    "neighbourhood_cleansed", #
    "property_type", # How a guest books space
    "amenities", # Basic items
    "review_scores_rating", #
    "estimated_occupancy_l365d",
    "price"              # Nightly rental price
]

rio_listings = df[target_columns].copy()

rio_listings.sample(5)

rio_listings.describe()

rio_listings.info()

"""tratamento da coluna preÃ§o"""

stripped_commas = rio_listings['price'].str.replace(',', '')

stripped_dollars = stripped_commas.str.replace('$', '')

rio_listings['price'] = stripped_dollars.astype('float')

rio_listings.dropna(axis=0, inplace=True)

ordem = rio_listings['property_type'].astype('category').unique().tolist()
rio_listings['property_type_cod'] = pd.Categorical(rio_listings['property_type'], categories=ordem, ordered=True)

rio_listings['property_type_cod'] = rio_listings['property_type_cod'].cat.codes

ordem = rio_listings['neighbourhood_cleansed'].astype('category').unique().tolist()
rio_listings['neighbourhood_cleansed_cod'] = pd.Categorical(rio_listings['neighbourhood_cleansed'], categories=ordem, ordered=True)

rio_listings['neighbourhood_cleansed_cod'] = rio_listings['neighbourhood_cleansed_cod'].cat.codes

ordem = rio_listings['amenities'].astype('category').unique().tolist()
rio_listings['amenities_cod'] = pd.Categorical(rio_listings['amenities'], categories=ordem, ordered=True)

rio_listings['amenities_cod'] = rio_listings['amenities_cod'].cat.codes

rio_listings.sample(5)

rio_listings = rio_listings.drop(['neighbourhood_cleansed', 'property_type', 'amenities'], axis=1)

rio_listings

from matplotlib.figure import Figure

# FunÃ§Ãµes de outliers
def _iqr_bounds(series: pd.Series, k: float = 1.5):
    q1 = series.quantile(0.25)
    q3 = series.quantile(0.75)
    iqr = q3 - q1
    low = q1 - k * iqr
    up = q3 + k * iqr
    return low, up, {"Q1": q1, "Q3": q3, "IQR": iqr}

def remove_outliers_iqr(df, columns, k=1.5, inclusive=True, dropna=True):
    data = df.copy()
    for c in columns:
        data[c] = pd.to_numeric(data[c], errors="coerce")
    if dropna:
        data = data.dropna(subset=columns)
    before = len(data)
    bounds = {}
    mask = pd.Series(True, index=data.index)
    for c in columns:
        low, up, stats = _iqr_bounds(data[c].dropna(), k=k)
        bounds[c] = {"low": low, "up": up, **stats}
        if inclusive:
            m = (data[c] >= low) & (data[c] <= up)
        else:
            m = (data[c] > low) & (data[c] < up)
        mask &= m
    cleaned = data.loc[mask].copy()
    info = {
        "rows_in": before,
        "rows_out": len(cleaned),
        "rows_removed": before - len(cleaned),
        "k": k,
        "inclusive": inclusive,
        "bounds": bounds,
    }
    return cleaned, info

# Aplica limpeza
rio_iqr_input = rio_listings.select_dtypes(include="number").copy()
rio_iqr, summary = remove_outliers_iqr(rio_iqr_input, list(rio_iqr_input.columns))

# FunÃ§Ã£o 1: Outliers
def aba_outliers():
    texto = f"**Rows before**: {summary['rows_in']}  \n"
    texto += f"**Rows after**: {summary['rows_out']}  \n"
    texto += f"**Removed**: {summary['rows_removed']}  \n\n"
    texto += "**Per-column bounds:**  \n"
    for col, b in summary["bounds"].items():
        texto += f"- `{col}`: [{b['low']:.3f}, {b['up']:.3f}] (Q1={b['Q1']:.3f}, Q3={b['Q3']:.3f}, IQR={b['IQR']:.3f})  \n"
    return texto

# FunÃ§Ã£o 2: Heatmap
def aba_heatmap():
    corr_matrix = rio_iqr.corr()
    fig = plt.figure(figsize=(20, 10))
    sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm", center=0, square=True, cbar_kws={"shrink": 0.75})
    plt.title("Correlation Heatmap of Rio Listings Features", fontsize=16, pad=15)
    plt.xticks(rotation=45, ha="right")
    plt.yticks(rotation=0)
    plt.tight_layout()
    return fig

# FunÃ§Ã£o 3: EstatÃ­sticas de price
def aba_descricao_price():
    return rio_iqr["price"].describe().to_frame().to_markdown()

# FunÃ§Ã£o 4: CorrelaÃ§Ã£o com price
def aba_correlacao_price():
    price_corr = rio_iqr.corr()["price"].sort_values(ascending=False)
    texto = "**CorrelaÃ§Ã£o com `price`:**  \n"
    for col, val in price_corr.items():
        texto += f"- `{col}`: {val:.3f}  \n"
    return texto

# FunÃ§Ã£o 5: Treinamento com PyTorch
def aba_treinamento(n_epochs):
    feature_cols = [c for c in rio_iqr.columns if c != "price"]
    target_col = "price"
    X = rio_iqr[feature_cols].to_numpy(dtype=np.float32)
    y = rio_iqr[target_col].to_numpy(dtype=np.float32).reshape(-1, 1)

    x_tensor = torch.as_tensor(X).float()
    y_tensor = torch.as_tensor(y).float()
    dataset = TensorDataset(x_tensor, y_tensor)

    ratio = 0.8
    n_total = len(dataset)
    n_train = int(n_total * ratio)
    n_val = n_total - n_train
    train_data, val_data = random_split(dataset, [n_train, n_val])

    train_loader = DataLoader(train_data, batch_size=16, shuffle=True)
    val_loader = DataLoader(val_data, batch_size=16, shuffle=False)

    class Architecture:
        def __init__(self, model, loss_fn, optimizer):
            self.model = model
            self.loss_fn = loss_fn
            self.optimizer = optimizer
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
            self.model.to(self.device)
            self.train_loader = None
            self.val_loader = None
            self.losses = []
            self.val_losses = []
            self.total_epochs = 0
            self.train_step_fn = self._make_train_step_fn()
            self.val_step_fn = self._make_val_step_fn()

        def set_loaders(self, train_loader, val_loader=None):
            self.train_loader = train_loader
            self.val_loader = val_loader

        def _make_train_step_fn(self):
            def fn(x, y):
                self.model.train()
                yhat = self.model(x)
                loss = self.loss_fn(yhat, y)
                loss.backward()
                self.optimizer.step()
                self.optimizer.zero_grad()
                return loss.item()
            return fn

        def _make_val_step_fn(self):
            def fn(x, y):
                self.model.eval()
                yhat = self.model(x)
                loss = self.loss_fn(yhat, y)
                return loss.item()
            return fn

        def _mini_batch(self, validation=False):
            loader = self.val_loader if validation else self.train_loader
            step_fn = self.val_step_fn if validation else self.train_step_fn
            losses = []
            for x, y in loader:
                x, y = x.to(self.device), y.to(self.device)
                losses.append(step_fn(x, y))
            return np.mean(losses)

        def set_seed(self, seed=42):
            torch.manual_seed(seed)
            np.random.seed(seed)

        def train(self, n_epochs, seed=42):
            self.set_seed(seed)
            for _ in range(n_epochs):
                self.total_epochs += 1
                self.losses.append(self._mini_batch(False))
                with torch.no_grad():
                    self.val_losses.append(self._mini_batch(True))

        def plot_losses(self):
          import matplotlib.pyplot as plt
          fig, ax = plt.subplots(figsize=(10, 4))

          if self.losses and self.val_losses:
              ax.plot(self.losses, label='Training Loss', color='blue')
              ax.plot(self.val_losses, label='Validation Loss', color='red')
              ax.set_yscale('log')
          else:
              ax.text(0.5, 0.5, 'Sem dados de perda disponÃ­veis', ha='center', va='center')

          ax.set_xlabel('Epochs')
          ax.set_ylabel('Loss')
          ax.legend()
          fig.tight_layout()
          return fig

    D = x_tensor.shape[1]
    model = nn.Sequential(nn.Linear(D, 1))
    optimizer = optim.SGD(model.parameters(), lr=0.001)
    loss_fn = nn.MSELoss()
    arch = Architecture(model, loss_fn, optimizer)
    arch.set_loaders(train_loader, val_loader)
    arch.train(n_epochs=n_epochs)

    return arch.plot_losses()

def aba_lazy():
    X = rio_iqr.drop("price", axis=1)
    y = rio_iqr["price"]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    linear_reg_model = LinearRegression()
    linear_reg_model.fit(X_train, y_train)
    y_pred = linear_reg_model.predict(X_test)

    fig = plt.figure(figsize=(10, 6))
    sns.scatterplot(x=y_test, y=y_pred)
    plt.title('Actual vs Predicted Prices (Linear Regression)', fontsize=16)
    plt.xlabel('Actual Price')
    plt.ylabel('Predicted Price')
    plt.grid(True)
    plt.tight_layout()


    return fig


demo = gr.TabbedInterface(
    interface_list=[
        gr.Interface(fn=aba_outliers, inputs=[], outputs=gr.Markdown(), title="RemoÃ§Ã£o de Outliers"),
        gr.Interface(fn=aba_heatmap, inputs=[], outputs=gr.Plot(), title="Heatmap de CorrelaÃ§Ã£o"),
        gr.Interface(fn=aba_descricao_price, inputs=[], outputs=gr.Markdown(), title="EstatÃ­sticas"),
        gr.Interface(fn=aba_correlacao_price, inputs=[], outputs=gr.Markdown(), title="CorrelaÃ§Ã£o"),
        gr.Interface(
      fn=aba_treinamento,
      inputs=gr.Slider(minimum=1, maximum=150, step=1, label="NÃºmero de Ã‰pocas"),
      outputs=gr.Plot(),
      title="ðŸ§  Treinamento com PyTorch"
  ),
        gr.Interface(fn=aba_lazy, inputs=[], outputs=[gr.Plot()], title="LazyRegressor + RegressÃ£o Linear")
    ],
    tab_names=[  "ðŸ” RemoÃ§Ã£o de Outliers",
        "ðŸŒ¡ï¸ Heatmap de CorrelaÃ§Ã£o",
        "ðŸ“Š EstatÃ­sticas de PreÃ§o",
        "ðŸ”— CorrelaÃ§Ã£o com PreÃ§o",
        "ðŸ§  Treinamento com PyTorch",
        "âš™ï¸ LazyRegressor + RegressÃ£o Linear"],
    title="RegressÃ£o Linear aplicada ao Dataset (Rio Listings)"
)

demo.launch(share=True)